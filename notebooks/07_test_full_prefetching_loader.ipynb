{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba del DataLoader\n",
    "\n",
    "**Objetivo:** \n",
    "* Instanciar y probar la clase `PrefetchingDataLoader` importada desde `src/prefetchingDataloader.py`.\n",
    "* Verificar que el prefetching funciona y comparar opcionalmente el rendimiento con y sin workers paralelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'c:\\fespa-dev\\nlp-curso\\nlp-proyecto01' ya está en sys.path\n"
     ]
    }
   ],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    print(f\"Añadido '{module_path}' a sys.path\")\n",
    "else:\n",
    "    print(f\"'{module_path}' ya está en sys.path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.prefetchingDataloader import PrefetchingDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cargando datos de 20 Newsgroups (subset 'train')...\n",
      "Se usarán 5000 documentos para la prueba.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCargando datos de 20 Newsgroups (subset 'train')...\")\n",
    "docs_all = fetch_20newsgroups(subset='all',\n",
    "                                remove=('headers', 'footers', 'quotes'),\n",
    "                                data_home='./data/20newsgroups_cache'\n",
    "                                ).data\n",
    "docs_subset = docs_all[:5000]\n",
    "print(f\"Se usarán {len(docs_subset)} documentos para la prueba.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_loader_test(loader_instance, test_name=\"Test\"):\n",
    "    \"\"\"Itera sobre un loader, mide tiempo e imprime resultados.\"\"\"\n",
    "    if not loader_instance:\n",
    "        print(f\"{test_name}: Instancia de loader no válida.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n--- {test_name} ---\")\n",
    "    print(f\"Iniciando consumo de ~{len(loader_instance)} lotes...\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    batch_count = 0\n",
    "    doc_count = 0\n",
    "    consumption_errors = 0\n",
    "\n",
    "    try:\n",
    "        for i, batch in enumerate(loader_instance):\n",
    "            batch_count += 1\n",
    "            # batch es list[list[list[str]]]\n",
    "            doc_count_in_batch = len(batch)\n",
    "            doc_count += doc_count_in_batch\n",
    "            # Imprimir progreso de forma dinámica\n",
    "            print(f\"  Consumido Lote {i+1}/{len(loader_instance)}. \"\n",
    "                  f\"Docs: {doc_count_in_batch}. \"\n",
    "                  f\"Buffer: ~{loader_instance.buffer.qsize()}   \", end='\\r')\n",
    "\n",
    "            # Simular trabajo del consumidor (ej. enviar a modelo)\n",
    "            # Un sleep más largo simula un consumidor más lento\n",
    "            time.sleep(0.1) # Ajusta este valor\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(f\"\\nERROR durante la iteración (posible error del productor): {e}\")\n",
    "        consumption_errors += 1\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR inesperado durante la iteración: {e}\")\n",
    "        consumption_errors += 1\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"\\n\" + \"-\"*len(test_name) + \"---\")\n",
    "    print(f\"{test_name}: Iteración finalizada.\")\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"  Tiempo total: {total_time:.2f} seg\")\n",
    "    print(f\"  Lotes recibidos: {batch_count}\")\n",
    "    print(f\"  Documentos procesados: {doc_count}\")\n",
    "    if consumption_errors > 0:\n",
    "        print(f\"  Errores durante consumo: {consumption_errors}\")\n",
    "    print(\"-\"*(len(test_name)+4))\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " INICIANDO PRUEBA SECUENCIAL (0 Workers)\n",
      "========================================\n",
      "\n",
      "--- Prueba Secuencial ---\n",
      "Iniciando consumo de ~40 lotes...\n",
      "[Productor]: Iniciado (Workers=0).\n",
      "[Productor]: Lote procesado (0.55s).\n",
      "[Productor]: Lote procesado (0.40s).ffer: ~0   \n",
      "[Productor]: Lote procesado (0.40s).ffer: ~0   \n",
      "[Productor]: Lote procesado (0.56s).ffer: ~0   \n",
      "[Productor]: Lote procesado (0.50s).ffer: ~0   \n",
      "[Productor]: Lote procesado (0.69s).ffer: ~0   \n",
      "[Productor]: Lote procesado (0.50s).ffer: ~0   \n",
      "[Productor]: Lote procesado (0.40s).ffer: ~0   \n",
      "[Productor]: Lote procesado (0.41s).ffer: ~0   \n",
      "[Productor]: Lote procesado (0.55s).ffer: ~0   \n",
      "[Productor]: Lote procesado (0.72s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.46s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.45s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.39s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.96s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.68s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.54s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.65s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.57s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.66s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.49s).uffer: ~0   \n",
      "[Productor]: Lote procesado (1.19s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.57s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.94s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.36s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.38s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.51s).uffer: ~0   \n",
      "[Productor]: Lote procesado (1.30s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.59s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.43s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.64s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.56s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.89s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.68s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.84s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.32s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.89s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.67s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.56s).uffer: ~0   \n",
      "[Productor]: Lote procesado (0.06s).uffer: ~0   \n",
      "[Productor]: Finalizado. Documentos procesados: 5000\n",
      "  Consumido Lote 40/40. Docs: 8. Buffer: ~1   \n",
      "--------------------\n",
      "Prueba Secuencial: Iteración finalizada.\n",
      "  Tiempo total: 24.08 seg\n",
      "  Lotes recibidos: 40\n",
      "  Documentos procesados: 5000\n",
      "---------------------\n",
      "\n",
      "pequeña pausa\n",
      "\n",
      "\n",
      "========================================\n",
      " INICIANDO PRUEBA PARALELA\n",
      "========================================\n",
      "\n",
      "--- Prueba Paralela (10 Workers) ---\n",
      "Iniciando consumo de ~40 lotes...\n",
      "[Productor]: Iniciado (Workers=10).\n",
      "[Productor]: Lote procesado (7.58s).\n",
      "[Productor]: Lote procesado (4.14s).ffer: ~0   \n",
      "[Productor]: Lote procesado (3.35s).ffer: ~0   \n",
      "[Productor]: Lote procesado (3.40s).ffer: ~0   \n",
      "[Productor]: Lote procesado (3.36s).ffer: ~0   \n",
      "[Productor]: Lote procesado (3.29s).ffer: ~0   \n",
      "[Productor]: Lote procesado (3.38s).ffer: ~0   \n",
      "[Productor]: Lote procesado (3.35s).ffer: ~0   \n",
      "[Productor]: Lote procesado (3.43s).ffer: ~0   \n",
      "[Productor]: Lote procesado (3.52s).ffer: ~0   \n",
      "[Productor]: Lote procesado (3.58s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.46s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.38s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.34s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.67s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.48s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.36s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.46s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.32s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.49s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.39s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.77s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.47s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.80s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.47s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.42s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.39s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.78s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.48s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.42s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.39s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.41s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.49s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.54s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.69s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.41s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.46s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.43s).uffer: ~0   \n",
      "[Productor]: Lote procesado (3.38s).uffer: ~0   \n",
      "[Productor]: Lote procesado (2.99s).uffer: ~0   \n",
      "[Productor]: Finalizado. Documentos procesados: 5000\n",
      "  Consumido Lote 40/40. Docs: 8. Buffer: ~1   \n",
      "-------------------------------\n",
      "Prueba Paralela (10 Workers): Iteración finalizada.\n",
      "  Tiempo total: 143.05 seg\n",
      "  Lotes recibidos: 40\n",
      "  Documentos procesados: 5000\n",
      "--------------------------------\n",
      "\n",
      "========================================\n",
      "        COMPARACIÓN DE TIEMPOS\n",
      "========================================\n",
      "Tiempo Secuencial : 24.08 seg\n",
      "Tiempo Paralelo   : 143.05 seg (10 workers)\n",
      "Speedup (Seq/Par): 0.17x\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Parámetros\n",
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 8\n",
    "\n",
    "# Prueba 1: Secuencial\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\" INICIANDO PRUEBA SECUENCIAL (0 Workers)\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "loader_seq = PrefetchingDataLoader(\n",
    "    documents=docs_subset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    buffer_size=BUFFER_SIZE,\n",
    "    num_workers=0\n",
    ")\n",
    "time_seq = run_loader_test(loader_seq, \"Prueba Secuencial\")\n",
    "\n",
    "# Pequeña pausa entre pruebas\n",
    "print(\"\\npequeña pausa\\n\")\n",
    "time.sleep(2)\n",
    "\n",
    "# Prueba 2: Paralelo\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\" INICIANDO PRUEBA PARALELA\")\n",
    "print(\"=\"*40)\n",
    "NUM_WORKERS_PARALLEL = 10\n",
    "loader_par = PrefetchingDataLoader(\n",
    "    documents=docs_subset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    buffer_size=BUFFER_SIZE,\n",
    "    num_workers=NUM_WORKERS_PARALLEL\n",
    ")\n",
    "time_par = run_loader_test(loader_par, f\"Prueba Paralela ({NUM_WORKERS_PARALLEL} Workers)\")\n",
    "\n",
    "#Comparación\n",
    "if time_seq is not None and time_par is not None and time_par > 0:\n",
    "    speedup = time_seq / time_par\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"        COMPARACIÓN DE TIEMPOS\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Tiempo Secuencial : {time_seq:.2f} seg\")\n",
    "    print(f\"Tiempo Paralelo   : {time_par:.2f} seg ({NUM_WORKERS_PARALLEL} workers)\")\n",
    "    print(f\"Speedup (Seq/Par): {speedup:.2f}x\")\n",
    "    print(\"=\"*40)\n",
    "elif time_seq is not None and time_par is not None:\n",
    "        print(\"\\nNo se puede calcular speedup (tiempo paralelo fue cero).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
